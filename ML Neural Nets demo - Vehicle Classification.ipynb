{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training Code\n",
    "Save model after compiling it, in case you have to press ^C during the execution of fit function.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "#from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 3\n",
    "nb_epoch = 300\n",
    "data_augmentation = True\n",
    "\n",
    "img_rows, img_cols = 50, 50\n",
    "img_channels = 3\n",
    "\n",
    "arr = numpy.load(\"trainAundh.npz\")\n",
    "X_train = 255 - arr['a']\n",
    "y_train = arr['b']\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "\n",
    "arr = numpy.load(\"testAundh.npz\")\n",
    "X_test = 255 - arr['a']\n",
    "y_test = arr['b']\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train -= 0.5\n",
    "X_test -= 0.5\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same',\n",
    "                        input_shape=(img_rows, img_cols, img_channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, W_regularizer=l2(0.1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, W_regularizer=l2(0.1)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#HERE: Save model after compiling it, in case you have to press ^C during the execution of fit function.\n",
    "model_json = model.to_json()\n",
    "with open(\"modelAundh.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "filename = \"modelAundh.h5\"\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callback_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "\t  callbacks=callback_list,\n",
    "          nb_epoch=nb_epoch,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code to check accuracies of trained models on any dataset.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "arr = numpy.load(\"trainAundh.npz\")\n",
    "X_train = 255 - arr['a']\n",
    "y_train = arr['b']\n",
    "\n",
    "#Load the dataset for which you want to get the accuracy.\n",
    "arr = numpy.load(\"testAundh.npz\")\n",
    "X_test = 255 - arr['a']\n",
    "y_test = arr['b']\n",
    "X_display = numpy.copy(X_test)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train -= 0.5\n",
    "X_test -= 0.5\n",
    "\n",
    "path = '../data/'\n",
    "model_name = 'modelAundh.json'\n",
    "\n",
    "json_file = open(model_name, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "\t      optimizer='adam',\n",
    "\t      metrics=['accuracy'])\n",
    "print(\"CNN Loaded\")\n",
    "loaded_model.summary()\n",
    "#Iterate over all the weights, run a forward pass, check accuracy\n",
    "for i in range(1, 6):\n",
    "\tweights_name = 'modelAundh.h5'\n",
    "\tloaded_model.load_weights(weights_name)\n",
    "\tall_predictions = loaded_model.predict(X_test, batch_size = 32, verbose = 0) #Gives class probabilities\n",
    "\tall_predictions = numpy.argmax(all_predictions, axis = 1) #Finds max probability. That is the output class of the image.\n",
    "\tall_predictions = all_predictions[:, numpy.newaxis] #Reshape to y_test.shape\n",
    "\terror = all_predictions == y_test #Find correctly classified images\n",
    "\tacc = float(numpy.sum(error))\n",
    "\tacc /= y_test.shape[0]\n",
    "\tacc *= 100\n",
    "\tprint('accuracy', acc)\n",
    "\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
